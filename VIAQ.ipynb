{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UUjQOwrZJluf"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HTcFJXxaqhTO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7aec3506-e893-4e42-d40f-39276bd71104"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xwwz4YvNuMKN"
      },
      "outputs": [],
      "source": [
        "data=pd.read_csv('/content/drive/MyDrive/Notebooks/University Campuss.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UlmjKPGpM8Xg"
      },
      "outputs": [],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RGAxl9p9NAaw"
      },
      "outputs": [],
      "source": [
        "data.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k6SvniWwiKbP"
      },
      "outputs": [],
      "source": [
        "for item in data.columns:\n",
        "  if item=='To Date':\n",
        "    continue\n",
        "  data[item]= data[item].astype('float')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FnIfxRNCkvbD"
      },
      "outputs": [],
      "source": [
        "data.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RICfIz6_aSz1"
      },
      "outputs": [],
      "source": [
        "\n",
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S8RK1cgMeQ_F"
      },
      "outputs": [],
      "source": [
        "null_item = []\n",
        "for item in data.columns:\n",
        "    if data[item].isnull().sum()>1:\n",
        "        null_item.append(item)\n",
        "\n",
        "for item in null_item:\n",
        "    print(f\"{item} has {np.round(data[item].isnull().mean()*100, 4)}% Missing Values\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KdBzmXNpM2bH"
      },
      "outputs": [],
      "source": [
        "\n",
        "data.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0fWkF45z7cLW"
      },
      "outputs": [],
      "source": [
        "for item in data.columns:\n",
        "  if item=='To Date':\n",
        "    continue\n",
        "  data[item]= data[item].interpolate(method='nearest')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IQtkaT9gQV_K"
      },
      "outputs": [],
      "source": [
        "data=data.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C9-tOkTy74Cb"
      },
      "outputs": [],
      "source": [
        "data.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VND5h-mp7b-X"
      },
      "outputs": [],
      "source": [
        "# Remove unused variables\n",
        "data = data.drop(['Battery (%)'],axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tWWEXHxXq9Fd"
      },
      "outputs": [],
      "source": [
        "# aaa = 5040\n",
        "# while aaa <= 5158:\n",
        "#   data = data.drop(aaa, axis=0)\n",
        "#   aaa = aaa + 1\n",
        "'''pos = []\n",
        "for i in range(1,31):\n",
        "  pos.append(i*2)\n",
        "\n",
        "CO = data[['CO (mg/m³)']]\n",
        "NO2 = data[['NO₂ (ppb)']]\n",
        "O3 = data[['SO₂ (ppb)']]\n",
        "PM25 = data[['PM₂.₅ (µg/m³)']]\n",
        "PM10 = data[['PM₁₀ (µg/m³)']]\n",
        "Temp = data[['Temperature (°C)']]\n",
        "\n",
        "test = [CO, NO2, O3, PM25, PM10, Temp]\n",
        "\n",
        "number = []\n",
        "\n",
        "for i in range(30):\n",
        "  for j in range(168):\n",
        "    number.append(i+1)\n",
        "\n",
        "data['week'] = number\n",
        "week2 = data[['week']]\n",
        "print(week2)\n",
        "print(type(week2))\n",
        "print(type(test[0]))\n",
        "\n",
        "seaborn.set(style = 'whitegrid')\n",
        "seaborn.boxplot(x='week', y='CO (mg/m³)', data=data)\n",
        "seaborn.boxplot(x='week', y='NO₂ (ppb)', data=data)\n",
        "seaborn.boxplot(x='week', y='SO₂ (ppb)', data=data)\n",
        "seaborn.boxplot(x='week', y='PM₂.₅ (µg/m³)', data=data)\n",
        "seaborn.boxplot(x='week', y='PM₁₀ (µg/m³)', data=data)\n",
        "seaborn.boxplot(x='week', y='Temperature (°C)', data=data )\n",
        "seaborn.despine(offset=10, trim=True)\n",
        "\n",
        "plt.show()\n",
        "# for z in range(6):\n",
        "#   seaborn.boxplot(x=week2, y=test[z])\n",
        "#   print(f\"{z+1} Completed.\")'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZH7oo_mH4Fup"
      },
      "outputs": [],
      "source": [
        "data = data[['CO (mg/m³)','NO₂ (ppb)','O₃ (ppb)','SO₂ (ppb)','PM₂.₅ (µg/m³)','PM₁₀ (µg/m³)','Temperature (°C)']]\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SPskXQsZIxfG"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "CONTINUOUS_VARIABLES = ['CO (mg/m³)',\n",
        "                       'NO₂ (ppb)',\n",
        "                       'O₃ (ppb)',\n",
        "                       'SO₂ (ppb)',\n",
        "                       'PM₂.₅ (µg/m³)',\n",
        "                       'PM₁₀ (µg/m³)']\n",
        "\n",
        "# create new dataframe containing only continuous variables\n",
        "cont_variables_dataframe = data[CONTINUOUS_VARIABLES]\n",
        "# calculate correlation for all continuous variables\n",
        "cont_variables_correlation = cont_variables_dataframe.corr()\n",
        "\n",
        "# plot the heatmap showing calculated correlations\n",
        "plt.subplots(figsize=(11, 11))\n",
        "plt.title('Pearson Correlation of continous features')\n",
        "ax = sns.heatmap(cont_variables_correlation,\n",
        "                 annot=True,\n",
        "                 linewidths=.5,\n",
        "                 cmap=sns.cubehelix_palette(as_cmap=True),\n",
        "                 square=True\n",
        "                );"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IFl2ogmB8PRJ"
      },
      "outputs": [],
      "source": [
        "data.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z2Dew1rEGzkz"
      },
      "outputs": [],
      "source": [
        "data.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I2JNvfotO1O3"
      },
      "outputs": [],
      "source": [
        "corr_data=data\n",
        "corr_bar=data\n",
        "PCA_data=data\n",
        "var_data=data\n",
        "AQI_data=data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2TLGy6r-lqxl"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "PCA_data=data\n",
        "'''PCA_data=PCA_data.drop(['ToDate'],axis=1)'''\n",
        "columns=PCA_data.columns.to_list()\n",
        "\n",
        "PCA_data = pd.DataFrame(PCA_data)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "PCA_data = scaler.fit_transform(PCA_data)\n",
        "PCA_data\n",
        "\n",
        "PCA_data = pd.DataFrame(PCA_data)\n",
        "PCA_data.columns=columns\n",
        "PCA_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p3gkU4FbR3hD"
      },
      "outputs": [],
      "source": [
        "pca = PCA(n_components=5)\n",
        "pca_result = pca.fit_transform(PCA_data.values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y5BnELlxTyko"
      },
      "outputs": [],
      "source": [
        "def pca_results(good_data, pca):\n",
        "\t'''\n",
        "\tCreate a DataFrame of the PCA results\n",
        "\tIncludes dimension feature weights and explained variance\n",
        "\tVisualizes the PCA results\n",
        "\t'''\n",
        "\n",
        "\t# Dimension indexing\n",
        "\tdimensions = dimensions = ['Dimension {}'.format(i) for i in range(1,len(pca.components_)+1)]\n",
        "\n",
        "\t# PCA components\n",
        "\tcomponents = pd.DataFrame(np.round(pca.components_, 4), columns = list(good_data.keys()))\n",
        "\tcomponents.index = dimensions\n",
        "\n",
        "\t# PCA explained variance\n",
        "\tratios = pca.explained_variance_ratio_.reshape(len(pca.components_), 1)\n",
        "\tvariance_ratios = pd.DataFrame(np.round(ratios, 4), columns = ['Explained Variance'])\n",
        "\tvariance_ratios.index = dimensions\n",
        "\n",
        "\t# Create a bar plot visualization\n",
        "\tfig, ax = plt.subplots(figsize = (14,8))\n",
        "\n",
        "\t# Plot the feature weights as a function of the components\n",
        "\tcomponents.plot(ax = ax, kind = 'bar');\n",
        "\tax.set_ylabel(\"Feature Weights\")\n",
        "\tax.set_xticklabels(dimensions, rotation=0)\n",
        "\n",
        "\n",
        "\t# Display the explained variance ratios\n",
        "\tfor i, ev in enumerate(pca.explained_variance_ratio_):\n",
        "\t\tax.text(i-0.40, ax.get_ylim()[1] + 0.05, \"Explained Variance\\n          %.4f\"%(ev))\n",
        "\n",
        "\t# Return a concatenated DataFrame\n",
        "\treturn pd.concat([variance_ratios, components], axis = 1)\n",
        "\n",
        "pca_results = pca_results(PCA_data, pca)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1RIWmL4N2tc"
      },
      "source": [
        "µg/m³= ppb* 12.187* MM/ (273.15+ C)\n",
        "\n",
        "µg/m³=ppm* 12.03* MM/ (273.15+C)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vlp75R4op62Q"
      },
      "outputs": [],
      "source": [
        "data['Temperature (°C)']= data['Temperature (°C)'] + 273.15\n",
        "data['SO₂ (ppb)']=data['SO₂ (ppb)']*779.6/data['Temperature (°C)']\n",
        "data['O₃ (ppb)']=data['O₃ (ppb)']*584.7/data['Temperature (°C)']\n",
        "#data['NO (ppb)']=data['NO (ppb)']*365.7/data['Temperature (°C)']\n",
        "data['NO₂ (ppb)']=data['NO₂ (ppb)']*560.7/data['Temperature (°C)']\n",
        "#data['CO₂ (ppm)']=data['CO₂ (ppm)']*529.7/data['Temperature (°C)']\n",
        "#data['CO (mg/m³)']=data['CO (mg/m³)']*1000\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "atj5CajH8gmG"
      },
      "outputs": [],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PMQOfZbktJFS"
      },
      "outputs": [],
      "source": [
        "data.rename(columns={'SO₂ (ppb)': 'SO₂ (µg/m³)', 'O₃ (ppb)': 'O₃ (µg/m³)', 'Temperature (°C)': 'Temperature (K)', 'NO₂ (ppb)': 'NO₂ (µg/m³)'}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z_M23SvMNb29"
      },
      "outputs": [],
      "source": [
        "data[\"PM10_24hr_avg\"] = data[\"PM₁₀ (µg/m³)\"].rolling(window = 24, min_periods = 16).mean().values\n",
        "data[\"PM2.5_24hr_avg\"] = data[\"PM₂.₅ (µg/m³)\"].rolling(window = 24, min_periods = 16).mean().values\n",
        "data[\"SO2_24hr_avg\"] = data[\"SO₂ (µg/m³)\"].rolling(window = 24, min_periods = 16).mean().values\n",
        "data[\"NO2_24hr_avg\"] = data[\"NO₂ (µg/m³)\"].rolling(window = 24, min_periods = 16).mean().values\n",
        "data[\"CO_8hr_max\"] = data[\"CO (mg/m³)\"].rolling(window = 8, min_periods = 1).max().values\n",
        "data[\"O3_8hr_max\"] = data[\"O₃ (µg/m³)\"].rolling(window = 8, min_periods = 1).max().values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y7g9TqUzc3r6"
      },
      "outputs": [],
      "source": [
        "## O3 Sub-Index calculation\n",
        "def get_O3_subindex(x):\n",
        "    if x <= 50:\n",
        "        return x * 50 / 50\n",
        "    elif x <= 100:\n",
        "        return 50 + (x - 50) * 50 / 50\n",
        "    elif x <= 168:\n",
        "        return 100 + (x - 100) * 100 / 68\n",
        "    elif x <= 208:\n",
        "        return 200 + (x - 168) * 100 / 40\n",
        "    elif x <= 748:\n",
        "        return 300 + (x - 208) * 100 / 539\n",
        "    elif x > 748:\n",
        "        return 400 + (x - 400) * 100 / 539\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "data[\"O3_SubIndex\"] = data[\"O3_8hr_max\"].apply(lambda x: get_O3_subindex(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "53vvvXiInkdM"
      },
      "outputs": [],
      "source": [
        "## CO Sub-Index calculation\n",
        "def get_CO_subindex(x):\n",
        "    if x <= 1:\n",
        "        return x * 50 / 1\n",
        "    elif x <= 2:\n",
        "        return 50 + (x - 1) * 50 / 1\n",
        "    elif x <= 10:\n",
        "        return 100 + (x - 2) * 100 / 8\n",
        "    elif x <= 17:\n",
        "        return 200 + (x - 10) * 100 / 7\n",
        "    elif x <= 34:\n",
        "        return 300 + (x - 17) * 100 / 17\n",
        "    elif x > 34:\n",
        "        return 400 + (x - 34) * 100 / 17\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "data[\"CO_SubIndex\"] = data[\"CO_8hr_max\"].apply(lambda x: get_CO_subindex(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IgqK7r9TRN-l"
      },
      "outputs": [],
      "source": [
        "## PM10 Sub-Index calculation\n",
        "def get_PM10_subindex(x):\n",
        "    if x <= 50:\n",
        "        return x\n",
        "    elif x <= 100:\n",
        "        return x\n",
        "    elif x <= 250:\n",
        "        return 100 + (x - 100) * 100 / 150\n",
        "    elif x <= 350:\n",
        "        return 200 + (x - 250)\n",
        "    elif x <= 430:\n",
        "        return 300 + (x - 350) * 100 / 80\n",
        "    elif x > 430:\n",
        "        return 400 + (x - 430) * 100 / 80\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "data[\"PM10_SubIndex\"] = data[\"PM10_24hr_avg\"].apply(lambda x: get_PM10_subindex(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lxpTTyDDQ_ol"
      },
      "outputs": [],
      "source": [
        "## PM2.5 Sub-Index calculation\n",
        "def get_PM25_subindex(x):\n",
        "    if x <= 30:\n",
        "        return x * 50 / 30\n",
        "    elif x <= 60:\n",
        "        return 50 + (x - 30) * 50 / 30\n",
        "    elif x <= 90:\n",
        "        return 100 + (x - 60) * 100 / 30\n",
        "    elif x <= 120:\n",
        "        return 200 + (x - 90) * 100 / 30\n",
        "    elif x <= 250:\n",
        "        return 300 + (x - 120) * 100 / 130\n",
        "    elif x > 250:\n",
        "        return 400 + (x - 250) * 100 / 130\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "data[\"PM2.5_SubIndex\"] = data[\"PM2.5_24hr_avg\"].apply(lambda x: get_PM25_subindex(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FTwe8mWdRhr2"
      },
      "outputs": [],
      "source": [
        "## SO2 Sub-Index calculation\n",
        "def get_SO2_subindex(x):\n",
        "    if x <= 40:\n",
        "        return x * 50 / 40\n",
        "    elif x <= 80:\n",
        "        return 50 + (x - 40) * 50 / 40\n",
        "    elif x <= 380:\n",
        "        return 100 + (x - 80) * 100 / 300\n",
        "    elif x <= 800:\n",
        "        return 200 + (x - 380) * 100 / 420\n",
        "    elif x <= 1600:\n",
        "        return 300 + (x - 800) * 100 / 800\n",
        "    elif x > 1600:\n",
        "        return 400 + (x - 1600) * 100 / 800\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "data[\"SO2_SubIndex\"] = data[\"SO2_24hr_avg\"].apply(lambda x: get_SO2_subindex(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hhojqypek4F7"
      },
      "outputs": [],
      "source": [
        "## NO2 Sub-Index calculation\n",
        "def get_NO2_subindex(x):\n",
        "    if x <= 40:\n",
        "        return x * 50 / 40\n",
        "    elif x <= 80:\n",
        "        return 50 + (x - 40) * 50 / 40\n",
        "    elif x <= 180:\n",
        "        return 100 + (x - 80) * 100 / 100\n",
        "    elif x <= 280:\n",
        "        return 200 + (x - 180) * 100 / 100\n",
        "    elif x <= 400:\n",
        "        return 300 + (x - 280) * 100 / 120\n",
        "    elif x > 400:\n",
        "        return 400 + (x - 400) * 100 / 120\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "data[\"NO2_SubIndex\"] = data[\"NO2_24hr_avg\"].apply(lambda x: get_NO2_subindex(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YlWek4hSrIfk"
      },
      "outputs": [],
      "source": [
        "## AQI bucketing\n",
        "def get_AQI_bucket(x):\n",
        "    if x <= 50:\n",
        "        return \"Good\"\n",
        "    elif x <= 100:\n",
        "        return \"Satisfactory\"\n",
        "    elif x <= 200:\n",
        "        return \"Moderate\"\n",
        "    elif x <= 300:\n",
        "        return \"Poor\"\n",
        "    elif x <= 400:\n",
        "        return \"Very Poor\"\n",
        "    elif x > 400:\n",
        "        return \"Severe\"\n",
        "    else:\n",
        "        return np.NaN\n",
        "\n",
        "data[\"Checks\"] = (data[\"PM2.5_SubIndex\"] > 0).astype(int) + \\\n",
        "                (data[\"PM10_SubIndex\"] > 0).astype(int) + \\\n",
        "                (data[\"SO2_SubIndex\"] > 0).astype(int) + \\\n",
        "                (data[\"NO2_SubIndex\"] > 0).astype(int) + \\\n",
        "                (data[\"CO_SubIndex\"] > 0).astype(int) + \\\n",
        "                (data[\"O3_SubIndex\"] > 0).astype(int)\n",
        "\n",
        "data[\"AQI_calculated\"] = round(data[[\"PM2.5_SubIndex\", \"PM10_SubIndex\", \"SO2_SubIndex\",\n",
        "                                 \"NO2_SubIndex\", \"CO_SubIndex\", \"O3_SubIndex\"]].max(axis = 1))\n",
        "data.loc[data[\"PM2.5_SubIndex\"] + data[\"PM10_SubIndex\"] <= 0, \"AQI_calculated\"] = np.NaN\n",
        "data.loc[data.Checks < 3, \"AQI_calculated\"] = np.NaN\n",
        "\n",
        "data[\"AQI_bucket_calculated\"] = data[\"AQI_calculated\"].apply(lambda x: get_AQI_bucket(x))\n",
        "data[~data.AQI_calculated.isna()].head(13)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4U_aLMyYqwVp"
      },
      "outputs": [],
      "source": [
        "data[~data.AQI_calculated.isna()].AQI_bucket_calculated.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gGS9TmWcrI9Y"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8,4),dpi=200)\n",
        "palette ={'Severe': \"brown\",'Very Poor': \"orangered\",\"Poor\": 'darkorange','Moderate': \"dodgerblue\",\"Satisfactory\":'lightskyblue','Good': \"green\"}\n",
        "sns.lineplot(x= 'AQI_calculated', y= 'PM₂.₅ (µg/m³)', data=data,hue ='AQI_bucket_calculated',palette =['yellowgreen','green','dodgerblue','lightskyblue','red'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "55XoDq5YsDgs"
      },
      "outputs": [],
      "source": [
        "Hum_AQI_Cor=data\n",
        "Hum_AQI_Cor=Hum_AQI_Cor.dropna()\n",
        "Hum_AQI_Cor.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GVNu6Za2D_Lw"
      },
      "outputs": [],
      "source": [
        "X = Hum_AQI_Cor.drop(['AQI_calculated'], axis=1)\n",
        "correlation_series = X.corrwith(Hum_AQI_Cor['AQI_calculated'])\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.scatter(\n",
        "    x=correlation_series.index,\n",
        "    y=correlation_series.values,\n",
        "    s=correlation_series.abs() * 1000,\n",
        "    alpha=0.7\n",
        ")\n",
        "plt.title(\"Correlation with AQI_calculated\")\n",
        "plt.xlabel(\"Variable\")\n",
        "plt.ylabel(\"Correlation\")\n",
        "plt.xticks(rotation=90)\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_kmQbUchAo2T"
      },
      "outputs": [],
      "source": [
        "data=data.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M8l9WCibL-Wa"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import statsmodels.api as sm\n",
        "\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error, accuracy_score, mean_squared_log_error\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u4lXpjaHoF8_"
      },
      "outputs": [],
      "source": [
        "models = pd.DataFrame(columns=[\"Model\",\"MAE\",\"MSE\",\"RMSE\",\"R2 Score\",\"RMSE (Cross-Validation)\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "We4RppRQKGy5"
      },
      "outputs": [],
      "source": [
        "important_num_cols = list(data.corr()[\"AQI_calculated\"][(data.corr()[\"AQI_calculated\"]>0.50) | (data.corr()[\"AQI_calculated\"]<-0.50)].index)\n",
        "cat_cols = [\"CO (mg/m³)\", \"NO₂ (µg/m³)\",\"O₃ (µg/m³)\",\"SO₂ (µg/m³)\",\"PM₁₀ (µg/m³)\",\"PM₂.₅ (µg/m³)\",'AQI_bucket_calculated']\n",
        "important_cols = important_num_cols + cat_cols\n",
        "\n",
        "data_cl= data[important_cols]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dDYvZUlvK_5X"
      },
      "outputs": [],
      "source": [
        "data_cl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lX6HxktvLNR6"
      },
      "outputs": [],
      "source": [
        "data_cl=data_cl.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vaRcogprLnOf"
      },
      "outputs": [],
      "source": [
        "data_cl.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0_N16tTdL5nF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12a29a57-0fb4-4188-856d-a835a37c0c6a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5144, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ],
      "source": [
        "data_cl.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CL0nfNEFL95l"
      },
      "outputs": [],
      "source": [
        "X=data_cl.drop(['AQI_bucket_calculated','PM10_24hr_avg','PM2.5_24hr_avg'], axis=1)\n",
        "y=data_cl['AQI_bucket_calculated']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7i2jmROqN00e"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O108XST5zi2f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import OrthogonalMatchingPursuit\n",
        "\n",
        "\n",
        "# Create an Orthogonal Matching Pursuit model\n",
        "omp = OrthogonalMatchingPursuit(n_nonzero_coefs=3)\n",
        "\n",
        "# Fit the model to the training data\n",
        "omp.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions using the trained model\n",
        "y_pred = omp.predict(X_test)\n"
      ],
      "metadata": {
        "id": "FgUcQloqIwgR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import ElasticNet\n",
        "\n",
        "# Create an Elastic Net model\n",
        "elastic_net = ElasticNet(alpha=1.0, l1_ratio=0.5)\n",
        "\n",
        "# Fit the model to the training data\n",
        "elastic_net.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions using the trained model\n",
        "y_pred = elastic_net.predict(X_test)\n"
      ],
      "metadata": {
        "id": "moiuutnszzat"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LassoLars\n",
        "\n",
        "\n",
        "# Create a LARS Lasso model\n",
        "lasso_lars = LassoLars(alpha=1.0)\n",
        "\n",
        "# Fit the model to the training data\n",
        "lasso_lars.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions using the trained model\n",
        "y_pred = lasso_lars.predict(X_test)\n"
      ],
      "metadata": {
        "id": "_jS19oCg0Lh1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import BayesianRidge\n",
        "\n",
        "\n",
        "# Create a Bayesian Ridge model\n",
        "bayesian_ridge = BayesianRidge()\n",
        "\n",
        "# Fit the model to the training data\n",
        "bayesian_ridge.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions using the trained model\n",
        "y_pred = bayesian_ridge.predict(X_test)\n"
      ],
      "metadata": {
        "id": "xg2BY_730m3w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "\n",
        "# Create a Ridge model\n",
        "ridge = Ridge(alpha=1.0)\n",
        "\n",
        "# Fit the model to the training data\n",
        "ridge.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions using the trained model\n",
        "y_pred = ridge.predict(X_test)\n"
      ],
      "metadata": {
        "id": "MjnPQtUu1Bfj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "\n",
        "# Create a GradientBoostingRegressor model\n",
        "gradient_boosting_regressor = GradientBoostingRegressor(n_estimators=50)\n",
        "\n",
        "# Fit the model to the training data\n",
        "gradient_boosting_regressor.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions using the trained model\n",
        "y_pred = gradient_boosting_regressor.predict(X_test)\n"
      ],
      "metadata": {
        "id": "xzmORI8AD5Yq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "# Create a DecisionTreeRegressor model\n",
        "decision_tree_regressor = DecisionTreeRegressor()\n",
        "\n",
        "# Fit the model to the training data\n",
        "decision_tree_regressor.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions using the trained model\n",
        "y_pred = decision_tree_regressor.predict(X_test)\n"
      ],
      "metadata": {
        "id": "D11rdf-BDs3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Lasso\n",
        "\n",
        "# Create a Lasso model\n",
        "lasso = Lasso(alpha=1.0)  # You can adjust the alpha parameter\n",
        "\n",
        "# Fit the model to the training data\n",
        "lasso.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions using the trained model\n",
        "y_pred = lasso.predict(X_test)\n"
      ],
      "metadata": {
        "id": "cXEvWQcV1qtg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "\n",
        "# Create a KNeighborsRegressor model\n",
        "knn_regressor = KNeighborsRegressor(n_neighbors=5)\n",
        "\n",
        "# Fit the model to the training data\n",
        "knn_regressor.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions using the trained model\n",
        "y_pred = knn_regressor.predict(X_test)\n"
      ],
      "metadata": {
        "id": "emsS5bnoEMcr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Create a LinearRegression model\n",
        "linear_regression = LinearRegression()\n",
        "\n",
        "# Fit the model to the training data\n",
        "linear_regression.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions using the trained model\n",
        "y_pred = linear_regression.predict(X_test)\n"
      ],
      "metadata": {
        "id": "nkSuX0-JEZ0l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import AdaBoostRegressor\n",
        "\n",
        "# Create an AdaBoostRegressor model\n",
        "adaboost_regressor = AdaBoostRegressor(n_estimators=50)  # You can adjust the number of estimators\n",
        "\n",
        "# Fit the model to the training data\n",
        "adaboost_regressor.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions using the trained model\n",
        "y_pred = adaboost_regressor.predict(X_test)\n"
      ],
      "metadata": {
        "id": "vk0C-IKN14kY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# Create a RandomForestRegressor model\n",
        "random_forest_regressor = RandomForestRegressor(n_estimators=50)  # You can adjust the number of estimators\n",
        "\n",
        "# Fit the model to the training data\n",
        "random_forest_regressor.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions using the trained model\n",
        "y_pred = random_forest_regressor.predict(X_test)\n"
      ],
      "metadata": {
        "id": "4WRev55DDJHC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import PassiveAggressiveRegressor\n",
        "\n",
        "# Create a PassiveAggressiveRegressor model\n",
        "passive_aggressive_regressor = PassiveAggressiveRegressor()\n",
        "\n",
        "# Fit the model to the training data\n",
        "passive_aggressive_regressor.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions using the trained model\n",
        "y_pred = passive_aggressive_regressor.predict(X_test)\n"
      ],
      "metadata": {
        "id": "ZYbuB6XcEgyW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.dummy import DummyRegressor\n",
        "\n",
        "# Create a DummyRegressor model\n",
        "dummy_regressor = DummyRegressor(strategy='mean')\n",
        "\n",
        "# Fit the model to the training data\n",
        "dummy_regressor.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions using the trained model\n",
        "y_pred = dummy_regressor.predict(X_test)\n"
      ],
      "metadata": {
        "id": "CS0rKglaE6IU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import ExtraTreesRegressor\n",
        "\n",
        "# Create an ExtraTreesRegressor model\n",
        "extra_trees_regressor = ExtraTreesRegressor(n_estimators=50)  # You can adjust the number of estimators\n",
        "\n",
        "# Fit the model to the training data\n",
        "extra_trees_regressor.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions using the trained model\n",
        "y_pred = extra_trees_regressor.predict(X_test)\n"
      ],
      "metadata": {
        "id": "edLpxcKQ2J6e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm as lgb\n",
        "\n",
        "# Create a LightGBMRegressor model\n",
        "lgbm_regressor = lgb.LGBMRegressor(n_estimators=50)  # You can adjust the number of estimators\n",
        "\n",
        "# Fit the model to the training data\n",
        "lgbm_regressor.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions using the trained model\n",
        "y_pred = lgbm_regressor.predict(X_test)\n"
      ],
      "metadata": {
        "id": "re9UVNhSDK3I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import HuberRegressor\n",
        "\n",
        "# Create a HuberRegressor model\n",
        "huber_regressor = HuberRegressor(epsilon=1.35)\n",
        "\n",
        "# Fit the model to the training data\n",
        "huber_regressor.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions using the trained model\n",
        "y_pred = huber_regressor.predict(X_test)\n"
      ],
      "metadata": {
        "id": "7f_vzQ59EvZk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Create a table to store the metrics\n",
        "metrics = pd.DataFrame(columns=['Model', 'MSE', 'MAE', 'RMSE', 'R-squared', 'RMSLE', 'MAPE'])\n",
        "\n",
        "# Calculate the metrics for each model\n",
        "models = [\n",
        "          'extra_trees_regressor',\n",
        "          'random_forest_regressor',\n",
        "          'lgbm_regressor',\n",
        "          'decision_tree_regressor',\n",
        "          'gradient_boosting_regressor',\n",
        "          'knn_regressor',\n",
        "          'linear_regression',\n",
        "          'bayesian_ridge',\n",
        "          'passive_aggressive_regressor',\n",
        "          'omp',\n",
        "          'ridge',\n",
        "          'lasso',\n",
        "          'adaboost_regressor',\n",
        "          'elastic_net',\n",
        "          'huber_regressor',\n",
        "          'lasso_larsn',\n",
        "          'dummy_regressor'\n",
        "]\n",
        "\n",
        "for model in models:\n",
        "\n",
        "    # Create a model\n",
        "    regressor = eval(model)\n",
        "\n",
        "    # Fit the model to the training data\n",
        "    regressor.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions on the test data\n",
        "    y_pred = regressor.predict(X_test)\n",
        "\n",
        "    # Calculate the metrics\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    rmsle = np.sqrt(mean_squared_log_error(y_test, y_pred))\n",
        "    mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
        "\n",
        "    # Add the metrics to the table\n",
        "    metrics = metrics.append({'Model': model, 'MSE': mse, 'MAE': mae, 'RMSE': rmse, 'R-squared': r2, 'RMSLE': rmsle, 'MAPE': mape}, ignore_index=True)\n",
        "\n",
        "# Display the table\n",
        "print(metrics)\n"
      ],
      "metadata": {
        "id": "OOw-wl7xF5xb"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}